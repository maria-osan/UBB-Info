{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbf0997-6524-4f39-8557-4d3522418083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import markovify\n",
    "from datasets import load_dataset\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ba0e86-974f-4e84-92ed-4fc9350128c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proverb generat:\n",
      "Ca musca in faina.\n"
     ]
    }
   ],
   "source": [
    "def generate_markov_chain(text):\n",
    "    words = text.split()\n",
    "    chain = {}\n",
    "    for i in range(len(words) - 1):\n",
    "        current_word = words[i]\n",
    "        next_word = words[i + 1]\n",
    "        if current_word in chain:\n",
    "            chain[current_word].append(next_word)\n",
    "        else:\n",
    "            chain[current_word] = [next_word]\n",
    "    return chain\n",
    "\n",
    "def generate_text(chain, length=10):\n",
    "    current_word = random.choice(list(chain.keys())).strip('.')\n",
    "    generated_text = [current_word]\n",
    "    for _ in range(length - 1):\n",
    "        if current_word in chain:\n",
    "            next_word = random.choice(chain[current_word])\n",
    "            next_word = next_word.strip('.')\n",
    "            generated_text.append(next_word)\n",
    "            current_word = next_word\n",
    "        else:\n",
    "            break\n",
    "    generated_text[-1] += '.'\n",
    "    return ' '.join(generated_text)\n",
    "\n",
    "# Read the text from the file\n",
    "with open('data/proverbe.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Generate the Markov chain\n",
    "chain = generate_markov_chain(text)\n",
    "\n",
    "# Generate a proverb using the Markov chain\n",
    "generated_proverb = generate_text(chain, length=10)\n",
    "print(\"Proverb generat:\")\n",
    "print(generated_proverb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3976da-f333-49d1-ad53-26faa77b53f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proverb generat:\n",
      "haina si nu haina pe om Omul face haina si.\n"
     ]
    }
   ],
   "source": [
    "def generate_markov_chain_n_states(text, n):\n",
    "    words = text.split()\n",
    "    chain = {}\n",
    "    for i in range(len(words) - n):\n",
    "        # Extract the current state, which is a tuple of n consecutive words\n",
    "        current_state = tuple(words[i:i + n])\n",
    "        # Get the next word after the current state\n",
    "        next_word = words[i + n]\n",
    "        # Update the chain dictionary with the current state and next word\n",
    "        if current_state in chain:\n",
    "            chain[current_state].append(next_word)\n",
    "        else:\n",
    "            chain[current_state] = [next_word]\n",
    "    return chain\n",
    "\n",
    "def generate_text_n_states(chain, n, length=10):\n",
    "    current_state = random.choice(list(chain.keys()))\n",
    "    generated_text = list(current_state)\n",
    "    for _ in range(length - n):\n",
    "        if current_state in chain:\n",
    "            # Randomly select the next word from the list of values associated with the current state\n",
    "            next_word = random.choice(chain[current_state])\n",
    "            generated_text.append(next_word)\n",
    "            current_state = tuple(generated_text[-n:])\n",
    "        else:\n",
    "            break\n",
    "    generated_text = [word.strip('.') for word in generated_text]\n",
    "    if not generated_text[-1].endswith('.'):\n",
    "        generated_text[-1] += '.'\n",
    "    return ' '.join(generated_text)\n",
    "\n",
    "# Read the text from the file\n",
    "with open('data/proverbe.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Specify the number of states\n",
    "n = 3\n",
    "\n",
    "chain = generate_markov_chain_n_states(text, n)\n",
    "\n",
    "# Generate a proverb using the Markov chain with n states\n",
    "generated_proverb = generate_text_n_states(chain, n, length=10)\n",
    "print(\"Proverb generat:\")\n",
    "print(generated_proverb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7004975-2b5b-4b35-be89-ff6e25159c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Poetry:\n",
      "Spake the stranger brawl\n",
      "Relate thee! Greater now in what she was, with pure gold.\n",
      "And by degrees of heav'n\n",
      "My kind and hospitable:.\n"
     ]
    }
   ],
   "source": [
    "def load_poetry_data():\n",
    "    # Load the Gutenberg Poetry Corpus\n",
    "    dataset = load_dataset(\"biglam/gutenberg-poetry-corpus\")\n",
    "    if \"train\" in dataset:\n",
    "        # Extract the poetry text\n",
    "        poetry_data = dataset[\"train\"]\n",
    "        poetry_text = \"\\n\".join(poetry_data[\"line\"])\n",
    "        return poetry_text\n",
    "    else:\n",
    "        print(\"Failed to load poetry data from the Gutenberg Poetry Corpus.\")\n",
    "        return None\n",
    "\n",
    "def generate_poetry(poetry_text):\n",
    "    if poetry_text:\n",
    "        # Train a Markov model\n",
    "        text_model = markovify.NewlineText(poetry_text, state_size=2)\n",
    "        # Generate a poetry\n",
    "        poetry = '\\n'.join([text_model.make_sentence(tries=100) for _ in range(4)])  # 4 lines\n",
    "        if not poetry.endswith((\".\", \"!\", \"?\", \";\")):\n",
    "            poetry += \".\"\n",
    "        return poetry\n",
    "    else:\n",
    "        return \"Failed to generate poetry stanza.\"\n",
    "\n",
    "\n",
    "# Load poetry data\n",
    "poetry_text = load_poetry_data()\n",
    "\n",
    "# Generate poetry\n",
    "generated_poetry = generate_poetry(poetry_text)\n",
    "\n",
    "# Print generated poetry\n",
    "print(\"Generated Poetry:\")\n",
    "print(generated_poetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4189a6c-f473-4bb5-ae33-b1dd54a59a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Polarity: 0.4380952380952381\n",
      "Sentiment Scores: 0.4380952380952381\n"
     ]
    }
   ],
   "source": [
    "def calculate_sentiment_textblob(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment_polarity = blob.sentiment.polarity\n",
    "    return sentiment_polarity\n",
    "\n",
    "def calculate_sentiment_nltk(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = sid.polarity_scores(text)\n",
    "    return sentiment_scores\n",
    "    \n",
    "\n",
    "# Calculate sentiment polarity of the generated poetry\n",
    "sentiment_polarity = calculate_sentiment_textblob(generated_poetry)\n",
    "print(\"Sentiment Polarity:\", sentiment_polarity)\n",
    "\n",
    "# Calculate sentiment score for the generated text\n",
    "sentiment_scores = calculate_sentiment_nltk(generated_poetry)\n",
    "print(\"Sentiment Scores:\", sentiment_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34289e8c-96d0-4c02-9aae-dc496e3c231f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Poetry:\n",
      "Spake the stranger brawl\n",
      "Relate thee! Greater now in what she was, with pure gold.\n",
      "And by degrees of heav'n\n",
      "My kind and hospitable:.\n",
      "\n",
      "Generated Poetry with Synonyms:\n",
      "Spake the stranger brawl pertain thee! greater now in what she was, with pure gold. And by degree of heav'n My kind and hospitable:.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import wordnet_ic\n",
    "\n",
    "# Încărcăm modelul spaCy cu embeddings\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def find_synonym(word):\n",
    "    max_similarity = -1\n",
    "    synonym = None\n",
    "    word_embedding = nlp(word).vector\n",
    "    \n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            lemma_embedding = nlp(lemma.name()).vector\n",
    "            similarity = np.dot(word_embedding, lemma_embedding) / (np.linalg.norm(word_embedding) * np.linalg.norm(lemma_embedding))\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                synonym = lemma.name()\n",
    "    \n",
    "    return synonym\n",
    "\n",
    "def replace_with_synonyms(poetry):\n",
    "    replaced_poetry = []\n",
    "    for word in poetry.split():\n",
    "        if wordnet.synsets(word):\n",
    "            synonym = find_synonym(word)\n",
    "            replaced_poetry.append(synonym)\n",
    "        else:\n",
    "            replaced_poetry.append(word)\n",
    "    return \" \".join(replaced_poetry)\n",
    "\n",
    "\n",
    "# Poezie generată\n",
    "print(\"Generated Poetry:\")\n",
    "print(generated_poetry)\n",
    "\n",
    "# Înlocuim cuvintele cu sinonime\n",
    "poetry_with_synonyms = replace_with_synonyms(generated_poetry)\n",
    "\n",
    "print(\"\\nGenerated Poetry with Synonyms:\")\n",
    "print(poetry_with_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d78fd-99c4-4ca1-a1eb-876b04123e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
